# تحليل عطل نفاد الذاكرة في أمر plan داخل مستودع team على GitHub

## خلفية المشكلة والأعراض

السجل الذي قدّمته يطابق نمط انهيار **Node.js/V8 بسبب نفاد ذاكرة الـ heap**: يظهر تكرار دورات GC من نوع Mark-Compact مع وصول الاستخدام إلى ~4 جيجابايت تقريباً، ثم رسالة قاتلة من V8:  
`FATAL ERROR: Reached heap limit Allocation failed - JavaScript heap out of memory`  
وهذا يعني أن العملية وصلت إلى **حدّ الذاكرة المسموح به للـ Old Space** ولم تعد قادرة على تخصيص ذاكرة إضافية. هذا السلوك متوافق مع توصيف وثائق Node.js لعلم `--max-old-space-size` بأنه يحدد الحد الأقصى لذاكرة “Old Space” في V8، ومع الاقتراب من الحد يقضي V8 وقتاً أطول في GC قبل أن يفشل إذا لم تستعد الذاكرة. citeturn25search0turn25search11

النقطة المهمّة عملياً: **وجود GC عند ~4050MB قبل الانهيار** يدل أن حد الـ heap مضبوط فعلياً حول 4096MB (4GB). رفع الحد قد يمنع الانهيار مؤقتاً، لكنه لا يعالج السبب الجذري إن كان هناك مسار عمل يحمّل ملفات/هياكل ضخمة أو يضمّن مجلدات مثل `node_modules` في التحليل. citeturn25search0turn25search8

## كيف يعمل أمر plan داخل المشروع

من معاينة بنية التنفيذ داخل المستودع (المشروع على entity["company","GitHub","code hosting platform"]) يتضح أن أمر `plan` يقوم – منطقياً – بثلاث خطوات عالية الحساسية للذاكرة:

1. قراءة ملف النتائج (findings) المخزن كـ JSON من artifacts (عادةً `findings.json`) ثم `JSON.parse` بالكامل داخل الذاكرة (أي تحميل النص + بناء الكائنات).
2. توليد خطة (plan) اعتماداً على findings، إما عبر استدعاء مولّد (قد يكون LLM) أو عبر مسار “fallback” يبني خطة تفصيلية.
3. (في حال وجود تحقق إضافي مثل فحوص barrel/index) قد يعيد بناء مشروع TypeScript/AST من جديد عبر ts-morph.

أي نقطة من هذه النقاط قد تضاعف استهلاك الذاكرة بسرعة إذا تم:
- تمرير JSON ضخم كاملاً كسلسلة،
- أو إنشاء Project يتضمن آلاف الملفات،
- أو استخدام glob عام يلتقط ملفات declaration (`.d.ts`) وملفات داخل `node_modules`.

## الأسباب المرجحة لنفاد الذاكرة

### تحميل artifacts كـ JSON كامل داخل الذاكرة

قراءة ملف JSON كبير طريقة مكلفة جداً: لديك نسختان كبيرتان في الذاكرة غالباً في نفس اللحظة:
- النص الخام (string) الناتج من `readFile`
- ثم الكائنات بعد `JSON.parse`

إذا كان `findings.json` كبيراً (حتى لو كان “بضعة مئات من الميجابايت”) يمكن أن يتحول إلى **جيجابايتات** في الذاكرة بسبب كلفة تمثيل النص والكائنات والـ overhead الخاص بالمحرك.

وثائق Node توضح أن تجاوز حدود heap يؤدي لانهيار “out-of-memory”، وأن ضبط `--max-old-space-size` يرفع الحد لكنه لا يمنع الانهيار إذا استمر الحمل في التضخم. citeturn25search8turn25search0

### بناء مشروع TypeScript عبر ts-morph بطريقة “تلتقط كل شيء”

ts-morph يدعم إضافة الملفات عبر globs، ويمكن أن تشمل `.d.ts` وملفات كثيرة جداً إذا استُخدم نمط واسع. الوثائق نفسها تعرض مثالاً يضيف `**/*{.d.ts,.ts}`، وكذلك توضّح إمكانية استخدام **negative patterns** لاستبعاد ملفات معينة مثل `!**/*.d.ts`. citeturn26search1turn24search0

المخاطر المعتادة التي ترفع الذاكرة بشكل انفجاري:

- استخدام glob من نوع `**/*.ts` أو `**/*.tsx` بدون استثناءات فعّالة  
  يؤدي غالباً إلى التقاط:
  - `index.d.ts` (لأنه ينتهي بـ `.ts`)  
  - ملفات تحت `node_modules` إذا كانت موجودة في مسار التحليل  
- الاعتماد على المسار النسبي أو `process.cwd()` دون تثبيت مسار repo المستهدف  
  معناه أن التحليل قد يحدث في **دليل غير مقصود**، وts-morph يذكر أن مطابقة/حلّ globs تُجرى **نسبةً إلى current working directory**. citeturn26search0

### حلّ التبعيات داخل ts-morph يوسع نطاق الملفات المحمّلة

عند إنشاء `Project` بوجود `tsConfigFilePath`، تقوم ts-morph – افتراضياً – بتضمين الملفات وربما تحليل اعتماداتها. الوثائق تذكر خياراً صريحاً لتجنب هذا التوسع: `skipFileDependencyResolution: true`. citeturn26search1

إذا كان مسار fallback يقوم بتحميل مشروع كامل أو يحلّ اعتمادات واسعة، فهذا وحده قد يستهلك عدة جيجابايتات على مشاريع كبيرة.

## حلول تشغيلية فورية لإيقاف الانهيار

هذه حلول “تشغيلية” لتجاوز الانهيار فوراً، لكنها ليست بديلاً عن الإصلاحات الجذرية:

### رفع حد الذاكرة (old space)

وثائق Node تصف `--max-old-space-size=SIZE` كحد بالميجابايت لذاكرة Old Space في V8. citeturn25search0turn25search11

إذا كانت العملية تنهار عند ~4096MB، جرّب عملياً:

- **8192MB (8GB)** كخطوة أولى
- ثم 12288MB إذا كان الجهاز يسمح (مع ترك هامش للـ OS وElectron وباقي العمليات)

أمثلة:

**Windows PowerShell (مؤقت للجلسة):**
```powershell
$env:NODE_OPTIONS="--max-old-space-size=8192"
pnpm engine:plan
```

**Windows CMD (مؤقت للجلسة):**
```bat
set NODE_OPTIONS=--max-old-space-size=8192
pnpm engine:plan
```

**تشغيل مباشر:**
```bash
node --max-old-space-size=8192 .../dist/cli/index.js plan <runId>
```

تنبيه منهجي: الرفع سيقلل احتمال الانهيار لكنه قد يخفي تسرباً أو مساراً يحمّل ملفات غير ضرورية. وثائق Node نفسها تلمّح إلى أن زيادة الحد مفيدة عندما يكون لديك بيانات طويلة العمر (Old Space) لكنها لا تُعفي من ضبط أسباب النمو غير المسيطر عليه. citeturn25search11turn25search8

### تقليل “نطاق” العمل مؤقتاً

إذا كانت الخطة تُبنى من findings تتضمن آلاف العناصر، وحتى قبل إصلاح الكود، يمكن مؤقتاً:
- تشغيل scan/plan على جزء أصغر من الريبو (إن كان tool يسمح بمسار فرعي أو فلتر).
- أو توليد plan لعدد محدود من findings (top-N) إن كان هناك خيار/إعداد.

هذا ليس علاجاً نهائياً، لكنه يثبت هل المشكلة “حجم بيانات” أم “التقاط مسارات خاطئة مثل node_modules”.

## إصلاحات جذرية مقترحة داخل الكود لمنع تضخم الذاكرة

الأولوية هنا هي منع *المسارات ذات الانفجار* (قراءة JSON ضخم + glob شامل + تضمين node_modules/decls).

### تضييق globs في ts-morph واستبعاد `.d.ts` و`node_modules`

ts-morph تسمح بإضافة ملفات عبر globs متعددة **وبأنماط نفي** مثل `!**/*.d.ts`. citeturn26search1  
كما توضح أن مطابقة globs تُحسب نسبةً إلى `cwd`، لذا يجب استخدام مسارات مطلقة أو تثبيت cwd بوضوح عند التحليل. citeturn26search0

نهج عملي قوي:
- إذا وُجد `tsconfig.json` في repo المستهدف: أنشئ Project بـ `tsConfigFilePath`  
- إن لم يوجد: استخدم `addSourceFilesAtPaths` لكن **بأنماط استبعاد واضحة**

والأهم: إن كان هدف التحقق هو فقط barrel files، فلا داعي لتحميل كل `.ts` في المشروع؛ حمّل فقط:
- `**/index.ts`
- `**/index.tsx`

لأن ذلك يخفض عدد الملفات من “عشرات الآلاف” إلى “مئات/آلاف” في أسوأ الحالات.

### إيقاف حلّ التبعيات في ts-morph عندما لا تحتاجه

إذا كان التحقق المطلوب لا يحتاج تحميل اعتمادات كل ملف، فعّل:
`skipFileDependencyResolution: true`  
كما هو موضح في وثائق إضافة الملفات في ts-morph. citeturn26search1

هذا يقلل سحب ملفات إضافية تلقائياً وبالتالي يقلل الذاكرة.

### عدم الاعتماد على `process.cwd()` لتحديد repo المستهدف

إذا كان مسار التحقق/التحليل يُشتق من `process.cwd()` أو globs نسبية، فهذا “مصدر خطر” لأن cwd في تطبيقات سطح المكتب/الحزم قد لا يساوي مسار الريبو الذي تم عمل scan له. ts-morph صريح في أن مطابقة المسارات/globs تتم نسبةً لـ cwd. citeturn26search0

الإصلاح البنيوي الأنظف:
- اعتبر `repo_path` (المسار الذي تم عمل scan عليه) جزءاً من run metadata داخل SQLite أو ضمن findings نفسها
- مرره صراحةً إلى مرحلة plan بدل guessing

### تقليل حجم artifacts على القرص لتقليل حمل الذاكرة عند القراءة

حتى لو لم تقدر على تطبيق parsing streaming فوراً، تقليل حجم JSON يقلل:
- زمن القراءة
- حجم النص في الذاكرة
- ضغط GC

أبسط تغيير:
- إيقاف pretty-print (إزالة `JSON.stringify(data, null, 2)` لصالح `JSON.stringify(data)` للملفات الضخمة مثل findings)  
هذا وحده قد يخفض الحجم بنسبة محسوسة.

تغيير أعلى جودة (لكن أكبر تنفيذاً):
- تخزين findings على شكل ملفات متعددة (مثلاً: `deadCode.json`, `duplicateFunctions.json`, …)  
بحيث plan يقرأ ما يحتاجه فقط.
- أو اعتماد ضغط (gzip) للملفات الكبيرة.

### استخدام fast-glob كطبقة انتقاء قبل ts-morph (اختياري لكن فعّال)

بدلاً من إعطاء ts-morph glob واسع، استخدم `fast-glob` أولاً لإحضار قائمة الملفات المطلوبة فقط (مثل index files) مع استثناءات دقيقة. fast-glob يعلن صراحةً دعم **multiple and negative patterns**. citeturn26search2  
وبذلك:
- تحصل على قائمة صغيرة من الملفات
- ثم تمرر هذه القائمة إلى ts-morph أو تحللها نصياً دون AST كامل

هذا يقلل مخاطر “التقاط غير مقصود” مثل node_modules.

## خطة تحقق وقياس بعد تطبيق الإصلاحات

### تأكيد حد heap الحالي ومراقبة النمو

وثائق Node (قسم diagnostics/memory) توضح استخدام `v8.getHeapStatistics()` لمعرفة `heap_size_limit` (حد heap). citeturn25search8turn25search11

اختبار سريع (يشغّل داخل نفس العملية/قبل العمل الثقيل):

```js
import v8 from "node:v8";

const { heap_size_limit } = v8.getHeapStatistics();
console.log("heap_size_limit(GB)=", heap_size_limit / (1024**3));
```

الهدف: التأكد أن حد heap فعلاً ارتفع عند ضبط `--max-old-space-size`.

### اختباران يجب إجراؤهما لتحديد السبب الجذري بدقة

1. **تشغيل plan مع تعطيل بناء Project (إن أضفت flag مؤقتاً)**  
   - إذا اختفى الانهيار: السبب الأساسي هو مسار ts-morph/globs
2. **تشغيل plan مع قراءة findings “مختصرة/مجزأة”**  
   - إذا اختفى الانهيار: السبب الأساسي هو حجم findings.json/طريقة قراءته

### معايير نجاح عملية واضحة

- إتمام plan بدون OOM عند حد 4096MB أو 8192MB (حسب حجم المشروع الواقعي)
- انخفاض واضح في زمن GC (لن ترى Mark-Compact الطويل المتكرر)  
- ثبات heapUsed وعدم نموّه بلا حدود أثناء plan

---

الخلاصة التنفيذية: السجل يثبت أن العملية تُسقِط نفسها عند حد ~4GB، ووفقاً لسلوك Node/V8 فهذا يتوافق تماماً مع نفاد Old Space. citeturn25search0turn25search11  
الاستراتيجية الصحيحة ليست “رفع الحد فقط”، بل **منع تضخم الذاكرة** عبر تضييق globs، استبعاد `.d.ts` و`node_modules`، تعطيل حلّ التبعيات عند عدم الحاجة، وتثبيت مسار repo المستهدف وعدم ربطه بـ cwd، مع تقليل حجم artifacts أو تجزئتها. citeturn26search1turn26search0turn26search2